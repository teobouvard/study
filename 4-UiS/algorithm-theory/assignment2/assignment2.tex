\documentclass[a4paper, 10pt, twoside]{article}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=3cm]{geometry}
\usepackage{amsmath}
\usepackage[shortlabels]{enumitem}
\usepackage{bbold}
\usepackage{cases}
\usepackage{clrscode3e}

\begin{document}

\title{Algorithm Theory - Assignment 3}
\author{T\'eo Bouvard}
\maketitle

\section*{Problem 1}
\begin{enumerate}[a)]
	\item If we can prove that $E$ has majority $e_m$ implies that  $E - \{e_i, e_j\}$ also has $e_m$ as majority, we can devise a simple algorithm that just removes pairs of distinct elements from the original sequence. At some point, one of two things is going to happen.

	      \begin{itemize}
		      \item We can't pick a pair of different elements because all elements in the sequence are identical. This implies that this repeating element is the majority of $E$.
		      \item We have an empty sequence. This implies that $E$ has no majority.
	      \end{itemize}

	      Here is the algorithm in pseudo code, which returns $\const{true}$ if $E$ has a majority and $\const{false}$ otherwise.

	      \begin{codebox}
		      \Procname{$\proc{majority}(E)$}
		      \zi \If $E = \emptyset$
		      \zi \Then \Return $\const{false}$ \End
		      \zi \If $\proc{all-equal(E)}$
		      \zi \Then \Return $\const{true}$ \End
		      \zi $pair \gets \proc{find-pair}(E)$
		      \zi \Return $\proc{majority}(E \setminus pair)$ \End
	      \end{codebox}

	      The above algorithm uses two subroutines.

	      \begin{itemize}
		      \item $\proc{all-equal}$ returns $\const{true}$ if all elements of a sequence are equal, and $\const{false}$ otherwise. We do not check for empty sequences as this subroutine is called after that condition is checked, in the first line of $\proc{majority}$.
		      \item $\proc{find-pair}$ returns a sequence of two distinct elements from the input sequence. We only need to consider sequences who actually have at least two distinct elements, because we checked for empty sets and sets containing identical elements before calling this subroutine.
	      \end{itemize}

	      \begin{codebox}
		      \Procname{$\proc{all-equal}(E)$}
		      \zi $elem \gets E[0]$
		      \zi \For $i \gets 1$ \To $\attrib{E}{length}$ \Do
		      \zi \If $elem \neq E[i]$
		      \zi \Then \Return $\const{false}$ \End \End
		      \zi \Return $\const{true}$ \End
	      \end{codebox}

	      \begin{codebox}
		      \Procname{$\proc{find-pair}(E)$}
		      \zi $first \gets E[0]$
		      \zi \For $k \gets 1$ \To $\attrib{E}{length}$ \Do
		      \zi \If $first \neq E[k]$
		      \zi \Then \Return $ \{ first, E[k] \} $ \End \End
	      \end{codebox}

	\item This problem has optimal substructure because the optimal solution is constructed from optimal solutions of its subproblems. However, there is no overlap among the subproblems. Dynamic programming requires both optimal substructure and overlapping subproblems to be applied, so we can't use it in this case.
\end{enumerate}

\section*{Problem 2}

This problem is an instance of the fractional knapsack problem. As Maria can get partial points if a problem is solved partially, her best strategy is to solve the problems having the highest point density first. That is, solve the problem with the highest $\frac{p_i}{t_i}$, until either the exam time runs out, in which case the algorithm exits, or the problem is solved, in which case she picks the next problem using the same rule.

\section*{Problem 3}

Let $X = \{ x_0, \ldots, x_n \}$ be the sequence of coordinates of all houses along the road, sorted in increasing order. Let $R$ be the coverage radius of a base station, in this case $R = 8$. If $X = \emptyset $, we do not need to place any base. If $X \neq \emptyset$, the first base we place should at least include $x_0$, and maximize the number of houses in its coverage radius in order to minimize the number of bases to place. These two conditions are sufficient to derive a greedy algorithm solving this problem. Let $b$ be the coordinate of the optimally placed first base.

\begin{itemize}
	\item The base should at least include $x_0 \implies \Vert b - x_0 \Vert \leq R$, otherwise the house is not close enough to be included in the coverage radius of the base.
	\item To maximize the area covered by the base, we should place it as far as possible from $x_0$. This implies $b = x_0 + R$ or $b = x_0 - R$
	\item As the coordinates are sorted in increasing order, we know that there are no houses before $x_0$ so choosing $b = x_0 -R $ would cover at most one house. However, there are possibly more houses after $x_0$, so choosing $b = x_0 + R$ is guaranteed to cover at least one house.
\end{itemize}

From the previous reasoning, we see that the optimal placement of the first base is $b = x_0 + R$.  We can then derive a recursive algorithm to solve this problem. The function $\proc{station-coordinates}$ returns a sequence representing the coordinates of the base stations. The number of base stations to be placed can be determined by checking the size of the sequence returned by the function. If we were only interested in the number of base stations to place, we could replace the sequence returned by additions. This is demonstrated in the $\proc{stations-counter}$ function.
For clarity, this algorithm modifies $X$ in-place by removing all covered houses each time a base station is placed. However, it would be more efficient (implementaion-wise) to not modify the sequence and just keep track of which houses are already covered, by keeping a pointer to the first house not covered, for example.

\begin{codebox}
	\Procname{$\proc{stations-coordinates}(X, R)$}
	\zi \If $X = \emptyset$
	\zi \Then \Return $\const{nil}$ \End
	\zi $firstHouse \gets X[0]$
	\zi \While $X \neq \emptyset \land X[0]  \leq firstHouse + R$
	\zi \Then $X \gets X \setminus X[0]$ \End
	\zi \Return $\proc{stations-coordinates}(X, R) \cup \{ firstHouse + R \}$ \End
\end{codebox}

\begin{codebox}
	\Procname{$\proc{stations-counter}(X, R)$}
	\zi \If $X = \emptyset$
	\zi \Then \Return 0 \End
	\zi $firstHouse \gets X[0]$
	\zi \While $X \neq \emptyset \land X[0]  \leq firstHouse + R$
	\zi \Then $X \gets X \setminus X[0]$ \End
	\zi \Return $\proc{stations-counter}(X, R) + 1$ \End
\end{codebox}

\section*{Problem 4}

I am not certain that the algorithm I found is really greedy, as it performs a linear scan of the sequence, but this is the only efficient way I found to solve this problem. The idea is to scan the sequence and keep track of the largest set at each time, comparing each new set with the largest one found until now.

\begin{codebox}
	\Procname{$\proc{largest-set}(X)$}
	\zi $maxlen \gets 0$
	\zi $maxseq \gets 0$
	\zi \For $i \gets 0$ \To $\attrib{X}{length}-1$ \Do
	\zi $j \gets i+1$
	\zi $n \gets 2$
	\zi \While $S[j] - S[i] \leq 1$ \Do
	\zi $j \gets j+1$
	\zi $n \gets n+1$ \End
	\zi \If $n-1 \ge maxlen$ \Do
	\zi $maxlen \gets n-1$
	\zi $maxseq \gets i$ \End
	\zi \Return $maxseq, maxlen$
\end{codebox}

This function returns the index of the first element in the largest set, and the length of this set. The outer loop is limited to the number of elements in the sequence, but the inner loop has a variable size. However, the inner loop is at most as long as the largest interval returned, so it loops for at most $maxlen$ iterations. As such, for a sequence of length $n$ having a largest interval of size $l$, the time complexity of this algorithm is $\mathcal{O}(n \times l)$. 

\end{document}
